#!/usr/bin/env python3
"""
æµ‹è¯•å“åº”ç»“æ„ä¿®å¤ - éªŒè¯è·¯ç”±ä¿®å¤æ˜¯å¦æ­£ç¡®
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_response_structure():
    """æµ‹è¯•å“åº”ç»“æ„ä¿®å¤"""
    
    print("ğŸ§ª æµ‹è¯•å“åº”ç»“æ„ä¿®å¤...")
    
    # æ¨¡æ‹ŸGenerationServiceçš„è¿”å›ç»“æœ
    mock_generation_result = {
        'success': True,
        'session_id': 'test_session_123',
        'message': 'æˆ‘å·²ç»æ”¶åˆ°äº†æ‚¨çš„ç”¨ä¾‹æ–‡ä»¶ã€‚ä¸ºäº†ç”Ÿæˆæ›´å‡†ç¡®çš„æµ‹è¯•ç”¨ä¾‹ï¼Œè¯·é—®ï¼š1. è¿™ä¸ªç³»ç»Ÿä¸»è¦çš„ç”¨æˆ·ç¾¤ä½“æ˜¯è°ï¼Ÿ2. æ˜¯å¦æœ‰ç‰¹æ®Šçš„å®‰å…¨æ€§è¦æ±‚ï¼Ÿ',  # Difyçš„çœŸå®å›å¤
        'initial_analysis': {
            'template_info': 'ç”¨ä¾‹æ¨¡æ¿åˆ†æå®Œæˆ',
            'description': 'æµ‹è¯•ç”¨ä¾‹å†…å®¹',
            'success': True
        },
        'auto_chat_started': True,  # å…³é”®æ ‡å¿—
        'files_processed': 1,
        'extracted_content': 'å®Œæ•´çš„ç”¨ä¾‹æè¿°å†…å®¹'
    }
    
    print("ğŸ“‹ GenerationServiceè¿”å›çš„æ•°æ®:")
    import json
    print(json.dumps(mock_generation_result, indent=2, ensure_ascii=False))
    
    # æ¨¡æ‹Ÿä¿®å¤åçš„è·¯ç”±é€»è¾‘
    def simulate_fixed_route_logic(result):
        """æ¨¡æ‹Ÿä¿®å¤åçš„è·¯ç”±é€»è¾‘"""
        if result['success']:
            response_data = {
                'success': True,
                'session_id': result['session_id'],
                'message': result.get('message', 'ä»»åŠ¡å¯åŠ¨æˆåŠŸ'),
                'analysis_result': result.get('analysis_result')
            }
            
            # ä¼ é€’è‡ªåŠ¨åˆ†æç›¸å…³çš„å­—æ®µ
            if result.get('auto_chat_started'):
                response_data['auto_chat_started'] = True
                response_data['initial_analysis'] = result.get('initial_analysis', {})
                response_data['files_processed'] = result.get('files_processed', 0)
                response_data['extracted_content'] = result.get('extracted_content', '')
            
            return response_data
        else:
            return {
                'success': False,
                'error': result['error'],
                'message': result['message']
            }
    
    # æµ‹è¯•ä¿®å¤åçš„é€»è¾‘
    frontend_response = simulate_fixed_route_logic(mock_generation_result)
    
    print("\nğŸ“¤ å‘é€ç»™å‰ç«¯çš„å“åº”:")
    print(json.dumps(frontend_response, indent=2, ensure_ascii=False))
    
    # éªŒè¯å…³é”®å­—æ®µ
    print("\nğŸ” éªŒè¯å…³é”®å­—æ®µ:")
    
    checks = [
        ('success', True, frontend_response.get('success')),
        ('session_id', 'test_session_123', frontend_response.get('session_id')),
        ('auto_chat_started', True, frontend_response.get('auto_chat_started')),
        ('messageåŒ…å«Difyå›å¤', True, 'Dify' not in frontend_response.get('message', '') or len(frontend_response.get('message', '')) > 20),
        ('initial_analysiså­˜åœ¨', True, 'initial_analysis' in frontend_response),
        ('extracted_contentå­˜åœ¨', True, 'extracted_content' in frontend_response)
    ]
    
    all_passed = True
    for check_name, expected, actual in checks:
        if expected == actual:
            print(f"âœ… {check_name}: {actual}")
        else:
            print(f"âŒ {check_name}: æœŸæœ› {expected}, å®é™… {actual}")
            all_passed = False
    
    return all_passed

def test_frontend_handling():
    """æµ‹è¯•å‰ç«¯å¤„ç†é€»è¾‘"""
    
    print("\nğŸ–¥ï¸ æµ‹è¯•å‰ç«¯å¤„ç†é€»è¾‘...")
    
    # æ¨¡æ‹Ÿå‰ç«¯æ”¶åˆ°çš„å“åº”
    frontend_response = {
        'success': True,
        'session_id': 'test_session_123',
        'message': 'æˆ‘å·²ç»æ”¶åˆ°äº†æ‚¨çš„ç”¨ä¾‹æ–‡ä»¶ã€‚ä¸ºäº†ç”Ÿæˆæ›´å‡†ç¡®çš„æµ‹è¯•ç”¨ä¾‹ï¼Œè¯·é—®ï¼š1. è¿™ä¸ªç³»ç»Ÿä¸»è¦çš„ç”¨æˆ·ç¾¤ä½“æ˜¯è°ï¼Ÿ2. æ˜¯å¦æœ‰ç‰¹æ®Šçš„å®‰å…¨æ€§è¦æ±‚ï¼Ÿ',
        'analysis_result': None,
        'auto_chat_started': True,
        'initial_analysis': {
            'template_info': 'ç”¨ä¾‹æ¨¡æ¿åˆ†æå®Œæˆ',
            'description': 'æµ‹è¯•ç”¨ä¾‹å†…å®¹',
            'success': True
        },
        'files_processed': 1,
        'extracted_content': 'å®Œæ•´çš„ç”¨ä¾‹æè¿°å†…å®¹'
    }
    
    # æ¨¡æ‹Ÿå‰ç«¯handleUploadCompleteé€»è¾‘
    def simulate_frontend_logic(response):
        """æ¨¡æ‹Ÿå‰ç«¯å¤„ç†é€»è¾‘"""
        messages_to_display = []
        
        if response.get('auto_chat_started'):
            print("ğŸ¤– æ£€æµ‹åˆ°è‡ªåŠ¨åˆ†æå·²å¯åŠ¨")
            
            # æ˜¾ç¤ºç”¨æˆ·å‘é€çš„æ¶ˆæ¯ï¼ˆåŒ…å«æ–‡ä»¶åå’Œç”¨ä¾‹æè¿°ï¼‰
            uploaded_file_name = "test_case_chinese.xml"  # æ¨¡æ‹Ÿæ–‡ä»¶å
            if uploaded_file_name and response.get('initial_analysis'):
                user_message = f"æˆ‘ä¸Šä¼ äº†ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹æ–‡ä»¶ï¼š{uploaded_file_name}\n\n"
                
                # å¦‚æœæœ‰æå–çš„ç”¨ä¾‹æè¿°ï¼Œæ˜¾ç¤ºå‡ºæ¥
                if response.get('extracted_content'):
                    user_message += f"ä»¥ä¸‹æ˜¯æ–‡ä»¶ä¸­çš„æµ‹è¯•ç”¨ä¾‹å†…å®¹ï¼š\n\n{response['extracted_content']}\n\n"
                
                user_message += "è¯·å¸®æˆ‘åˆ†æè¿™ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼Œå¹¶æå‡ºå®Œå–„å»ºè®®ã€‚æˆ‘å¸Œæœ›èƒ½å¤Ÿç”Ÿæˆæ›´å®Œæ•´å’Œè§„èŒƒçš„æµ‹è¯•ç”¨ä¾‹ã€‚"
                
                messages_to_display.append(("user", user_message))
            
            # æ˜¾ç¤ºAIçš„å›å¤ï¼ˆDifyçš„å“åº”ï¼‰
            if response.get('message'):
                messages_to_display.append(("ai", response['message']))
        
        return messages_to_display
    
    messages = simulate_frontend_logic(frontend_response)
    
    print("ğŸ“± å‰ç«¯å°†æ˜¾ç¤ºçš„æ¶ˆæ¯:")
    for i, (sender, message) in enumerate(messages, 1):
        print(f"\n{i}. {sender.upper()}æ¶ˆæ¯:")
        print(f"   {message[:100]}{'...' if len(message) > 100 else ''}")
    
    # éªŒè¯æ¶ˆæ¯æ•°é‡å’Œå†…å®¹
    if len(messages) == 2:
        user_msg = messages[0][1]
        ai_msg = messages[1][1]
        
        if "ä¸Šä¼ äº†ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹æ–‡ä»¶" in user_msg and "æµ‹è¯•ç”¨ä¾‹å†…å®¹" in user_msg:
            print("âœ… ç”¨æˆ·æ¶ˆæ¯åŒ…å«æ–‡ä»¶ä¿¡æ¯å’Œç”¨ä¾‹å†…å®¹")
        else:
            print("âŒ ç”¨æˆ·æ¶ˆæ¯ç¼ºå°‘å¿…è¦ä¿¡æ¯")
            return False
        
        if len(ai_msg) > 20 and ("ç”¨æˆ·ç¾¤ä½“" in ai_msg or "å®‰å…¨æ€§è¦æ±‚" in ai_msg):
            print("âœ… AIæ¶ˆæ¯æ˜¯Difyçš„çœŸå®å›å¤")
        else:
            print("âŒ AIæ¶ˆæ¯ä¸æ˜¯é¢„æœŸçš„Difyå›å¤")
            return False
        
        return True
    else:
        print(f"âŒ æ¶ˆæ¯æ•°é‡é”™è¯¯: æœŸæœ›2æ¡, å®é™…{len(messages)}æ¡")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•å“åº”ç»“æ„ä¿®å¤...")
    
    try:
        # æµ‹è¯•åç«¯å“åº”ç»“æ„
        backend_ok = test_response_structure()
        
        # æµ‹è¯•å‰ç«¯å¤„ç†é€»è¾‘
        frontend_ok = test_frontend_handling()
        
        if backend_ok and frontend_ok:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
            print("\nğŸ“ ä¿®å¤æ€»ç»“:")
            print("- âœ… åç«¯è·¯ç”±ç°åœ¨æ­£ç¡®ä¼ é€’æ‰€æœ‰å¿…è¦å­—æ®µ")
            print("- âœ… auto_chat_startedæ ‡å¿—æ­£ç¡®ä¼ é€’")
            print("- âœ… Difyçš„çœŸå®å›å¤æ¶ˆæ¯æ­£ç¡®ä¼ é€’")
            print("- âœ… å‰ç«¯èƒ½å¤Ÿæ­£ç¡®å¤„ç†å’Œæ˜¾ç¤ºæ¶ˆæ¯")
            print("\nğŸ”§ ç”¨æˆ·ç°åœ¨åº”è¯¥èƒ½çœ‹åˆ°:")
            print("- ç”¨æˆ·æ¶ˆæ¯ï¼šåŒ…å«æ–‡ä»¶åå’Œç”¨ä¾‹å†…å®¹")
            print("- AIæ¶ˆæ¯ï¼šDifyçš„çœŸå®åˆ†æå’Œé—®é¢˜")
            print("- æ­£å¸¸çš„å¯¹è¯æµç¨‹")
        else:
            print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
            if not backend_ok:
                print("- åç«¯å“åº”ç»“æ„æœ‰é—®é¢˜")
            if not frontend_ok:
                print("- å‰ç«¯å¤„ç†é€»è¾‘æœ‰é—®é¢˜")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()